{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Installations, imports, utils"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2024-05-29T08:18:38.003311Z","iopub.status.busy":"2024-05-29T08:18:38.002994Z","iopub.status.idle":"2024-05-29T08:19:39.273547Z","shell.execute_reply":"2024-05-29T08:19:39.272276Z","shell.execute_reply.started":"2024-05-29T08:18:38.003284Z"},"trusted":true},"outputs":[],"source":["!pip install -q -U transformers\n","!pip install -q -U accelerate\n","!pip install -q -U bitsandbytes"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T08:19:39.275864Z","iopub.status.busy":"2024-05-29T08:19:39.275537Z","iopub.status.idle":"2024-05-29T08:19:58.212530Z","shell.execute_reply":"2024-05-29T08:19:58.211439Z","shell.execute_reply.started":"2024-05-29T08:19:39.275825Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting langchain-communityNote: you may need to restart the kernel to use updated packages.\n","\n","  Using cached langchain_community-0.2.7-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: langchain-core in c:\\users\\apoor\\anaconda3\\envs\\project\\lib\\site-packages (0.2.18)\n","Requirement already satisfied: PyYAML>=5.3 in c:\\users\\apoor\\anaconda3\\envs\\project\\lib\\site-packages (from langchain-community) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\apoor\\anaconda3\\envs\\project\\lib\\site-packages (from langchain-community) (2.0.30)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\apoor\\anaconda3\\envs\\project\\lib\\site-packages (from langchain-community) (3.9.5)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n","  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n","Requirement already satisfied: langchain<0.3.0,>=0.2.7 in c:\\users\\apoor\\anaconda3\\envs\\project\\lib\\site-packages (from langchain-community) (0.2.7)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\apoor\\anaconda3\\envs\\project\\lib\\site-packages (from langchain-community) (0.1.85)\n","Requirement already satisfied: numpy<2,>=1 in c:\\users\\apoor\\anaconda3\\envs\\project\\lib\\site-packages (from langchain-community) (1.24.3)\n","Requirement already satisfied: requests<3,>=2 in c:\\users\\apoor\\anaconda3\\envs\\project\\lib\\site-packages (from langchain-community) (2.32.2)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\apoor\\anaconda3\\envs\\project\\lib\\site-packages (from langchain-community) (8.2.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\apoor\\anaconda3\\envs\\project\\lib\\site-packages (from langchain-core) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\apoor\\anaconda3\\envs\\project\\lib\\site-packages (from langchain-core) (23.2)\n","Requirement already satisfied: pydantic<3,>=1 in c:\\users\\apoor\\anaconda3\\envs\\project\\lib\\site-packages (from langchain-core) (2.5.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\apoor\\anaconda3\\envs\\project\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n","Requirement already satisfied: attrs>=17.3.0 in c:\\users\\apoor\\anaconda3\\envs\\project\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\apoor\\anaconda3\\envs\\project\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\apoor\\anaconda3\\envs\\project\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\apoor\\anaconda3\\envs\\project\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.3)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\apoor\\anaconda3\\envs\\project\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n","  Using cached marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n","Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n","  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\apoor\\anaconda3\\envs\\project\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (2.1)\n","Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\apoor\\anaconda3\\envs\\project\\lib\\site-packages (from langchain<0.3.0,>=0.2.7->langchain-community) (0.2.2)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\apoor\\anaconda3\\envs\\project\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.9.15)\n","Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\apoor\\anaconda3\\envs\\project\\lib\\site-packages (from pydantic<3,>=1->langchain-core) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\apoor\\anaconda3\\envs\\project\\lib\\site-packages (from pydantic<3,>=1->langchain-core) (2.14.6)\n","Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\apoor\\anaconda3\\envs\\project\\lib\\site-packages (from pydantic<3,>=1->langchain-core) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\apoor\\anaconda3\\envs\\project\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\apoor\\anaconda3\\envs\\project\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\apoor\\anaconda3\\envs\\project\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.2.2)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\apoor\\anaconda3\\envs\\project\\lib\\site-packages (from requests<3,>=2->langchain-community) (2024.7.4)\n","Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\apoor\\anaconda3\\envs\\project\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.1)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n","  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n","Using cached langchain_community-0.2.7-py3-none-any.whl (2.2 MB)\n","Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Using cached marshmallow-3.21.3-py3-none-any.whl (49 kB)\n","Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community\n","Successfully installed dataclasses-json-0.6.7 langchain-community-0.2.7 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"]}],"source":["pip install --upgrade langchain-community langchain-core"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'pandas'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"]}],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":2,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-05-29T08:20:29.519678Z","iopub.status.busy":"2024-05-29T08:20:29.519167Z","iopub.status.idle":"2024-05-29T08:20:36.489138Z","shell.execute_reply":"2024-05-29T08:20:36.488381Z","shell.execute_reply.started":"2024-05-29T08:20:29.519633Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["d:\\Minor Project\\Exam preparator\\.conda\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from torch import cuda, bfloat16\n","import torch\n","import transformers\n","from transformers import AutoTokenizer\n","from time import time\n","#import chromadb\n","#from chromadb.config import Settings\n","from langchain.llms import HuggingFacePipeline\n","from langchain.document_loaders import TextLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.chains import RetrievalQA\n","from langchain.vectorstores import Chroma\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T08:20:39.814037Z","iopub.status.busy":"2024-05-29T08:20:39.813198Z","iopub.status.idle":"2024-05-29T08:20:40.077740Z","shell.execute_reply":"2024-05-29T08:20:40.076819Z","shell.execute_reply.started":"2024-05-29T08:20:39.813999Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n"]},{"ename":"ValueError","evalue":"Invalid token passed!","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[8], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m token \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHUGGINGFACE_TOKEN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Log in to Hugging Face\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     \u001b[43mlogin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessfully logged in to Hugging Face!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[1;32md:\\Minor Project\\Exam preparator\\.conda\\lib\\site-packages\\huggingface_hub\\_login.py:111\u001b[0m, in \u001b[0;36mlogin\u001b[1;34m(token, add_to_git_credential, new_session, write_permission)\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m add_to_git_credential:\n\u001b[0;32m    105\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    106\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe token has not been saved to the git credentials helper. Pass \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    107\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`add_to_git_credential=True` in this function directly or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`--add-to-git-credential` if using via `huggingface-cli` if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    109\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou want to set the git credential as well.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    110\u001b[0m         )\n\u001b[1;32m--> 111\u001b[0m     \u001b[43m_login\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_to_git_credential\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_to_git_credential\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrite_permission\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_permission\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_notebook():\n\u001b[0;32m    113\u001b[0m     notebook_login(new_session\u001b[38;5;241m=\u001b[39mnew_session, write_permission\u001b[38;5;241m=\u001b[39mwrite_permission)\n","File \u001b[1;32md:\\Minor Project\\Exam preparator\\.conda\\lib\\site-packages\\huggingface_hub\\_login.py:307\u001b[0m, in \u001b[0;36m_login\u001b[1;34m(token, add_to_git_credential, write_permission)\u001b[0m\n\u001b[0;32m    305\u001b[0m permission \u001b[38;5;241m=\u001b[39m get_token_permission(token)\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m permission \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 307\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid token passed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m write_permission \u001b[38;5;129;01mand\u001b[39;00m permission \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    310\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToken is valid but is \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread-only\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m token is required.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPlease provide a new token with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    311\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m correct permission.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    312\u001b[0m     )\n","\u001b[1;31mValueError\u001b[0m: Invalid token passed!"]}],"source":["from dotenv import load_dotenv\n","import os\n","from huggingface_hub import login\n","\n","# Load environment variables from .env file\n","load_dotenv()\n","\n","# Retrieve the Hugging Face token from the environment variable\n","token = os.getenv(\"HUGGINGFACE_TOKEN\")\n","\n","if token:\n","    # Log in to Hugging Face\n","    login(token=token)\n","    print(\"Successfully logged in to Hugging Face!\")\n","else:\n","    print(\"Hugging Face token not found. Please set it in the .env file.\")"]},{"cell_type":"markdown","metadata":{},"source":["# Initialize model, tokenizer, query pipeline"]},{"cell_type":"markdown","metadata":{},"source":["Define the model, the device, and the `bitsandbytes` configuration."]},{"cell_type":"code","execution_count":9,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-05-29T08:20:42.620307Z","iopub.status.busy":"2024-05-29T08:20:42.619916Z","iopub.status.idle":"2024-05-29T08:20:42.630202Z","shell.execute_reply":"2024-05-29T08:20:42.629055Z","shell.execute_reply.started":"2024-05-29T08:20:42.620274Z"},"trusted":true},"outputs":[],"source":["model_id = 'mistralai/Mistral-7B-Instruct-v0.2'\n","\n","bnb_config = transformers.BitsAndBytesConfig(\n","    load_in_4bit=True\n",")"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["d:\\Minor Project\\Exam preparator\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]d:\\Minor Project\\Exam preparator\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\apoor\\.cache\\huggingface\\hub\\models--SweatyCrayfish--llama-3-8b-quantized. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n","To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n","  warnings.warn(message)\n","Fetching 1 files: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n"]},{"ename":"ValidationError","evalue":"1 validation error for CTransformers\n__root__\n  No model file found in repo 'SweatyCrayfish/llama-3-8b-quantized' (type=value_error)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CTransformers\n\u001b[1;32m----> 2\u001b[0m llm\u001b[38;5;241m=\u001b[39m\u001b[43mCTransformers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSweatyCrayfish/llama-3-8b-quantized\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mllama\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_new_tokens\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32md:\\Minor Project\\Exam preparator\\.venv\\Lib\\site-packages\\pydantic\\v1\\main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n","\u001b[1;31mValidationError\u001b[0m: 1 validation error for CTransformers\n__root__\n  No model file found in repo 'SweatyCrayfish/llama-3-8b-quantized' (type=value_error)"]}],"source":["from langchain_community.llms import CTransformers\n","llm=CTransformers(model='SweatyCrayfish/llama-3-8b-quantized',\n","                      model_type='llama',\n","                      config={'max_new_tokens':256,\n","                              'temperature':0.01})"]},{"cell_type":"markdown","metadata":{},"source":["Prepare the model and the tokenizer."]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T08:20:45.005745Z","iopub.status.busy":"2024-05-29T08:20:45.005356Z","iopub.status.idle":"2024-05-29T08:25:03.169771Z","shell.execute_reply":"2024-05-29T08:25:03.168910Z","shell.execute_reply.started":"2024-05-29T08:20:45.005715Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading shards: 100%|██████████| 3/3 [34:29<00:00, 689.84s/it]\n"]},{"ename":"RuntimeError","evalue":"CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtransformers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbnb_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[1;32md:\\Minor Project\\Exam preparator\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:563\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    562\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    567\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    569\u001b[0m )\n","File \u001b[1;32md:\\Minor Project\\Exam preparator\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:3685\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3680\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m   3681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis model has some weights that should be kept in higher precision, you need to upgrade \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3682\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`accelerate` to properly deal with them (`pip install --upgrade accelerate`).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3683\u001b[0m     )\n\u001b[0;32m   3684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device_map \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequential\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 3685\u001b[0m     max_memory \u001b[38;5;241m=\u001b[39m \u001b[43mget_balanced_memory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3686\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3687\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3688\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_zero\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbalanced_low_0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3689\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3690\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdevice_map_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3691\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3692\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3693\u001b[0m     max_memory \u001b[38;5;241m=\u001b[39m get_max_memory(max_memory)\n","File \u001b[1;32md:\\Minor Project\\Exam preparator\\.venv\\Lib\\site-packages\\accelerate\\utils\\modeling.py:957\u001b[0m, in \u001b[0;36mget_balanced_memory\u001b[1;34m(model, max_memory, no_split_module_classes, dtype, special_dtypes, low_zero)\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;66;03m# Get default / clean up max_memory\u001b[39;00m\n\u001b[0;32m    956\u001b[0m user_not_set_max_memory \u001b[38;5;241m=\u001b[39m max_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 957\u001b[0m max_memory \u001b[38;5;241m=\u001b[39m \u001b[43mget_max_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_memory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_npu_available():\n\u001b[0;32m    960\u001b[0m     num_devices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m([d \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m max_memory \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdevice(d)\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m max_memory[d] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m])\n","File \u001b[1;32md:\\Minor Project\\Exam preparator\\.venv\\Lib\\site-packages\\accelerate\\utils\\modeling.py:825\u001b[0m, in \u001b[0;36mget_max_memory\u001b[1;34m(max_memory)\u001b[0m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    824\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()):\n\u001b[1;32m--> 825\u001b[0m             _ \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    826\u001b[0m         max_memory \u001b[38;5;241m=\u001b[39m {i: torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmem_get_info(i)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count())}\n\u001b[0;32m    827\u001b[0m \u001b[38;5;66;03m# allocate everything in the mps device as the RAM is shared\u001b[39;00m\n","\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"]}],"source":["\n","model = transformers.AutoModelForCausalLM.from_pretrained(\n","    model_id,\n","    trust_remote_code=True,\n","    quantization_config=bnb_config,\n","    torch_dtype=torch.float16,\n","    \n","    device_map='auto',\n",")\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Is CUDA available: True\n"]}],"source":["import torch\n","print(f\"Is CUDA available: {torch.cuda.is_available()}\")"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T08:25:57.904596Z","iopub.status.busy":"2024-05-29T08:25:57.903652Z","iopub.status.idle":"2024-05-29T08:25:58.883404Z","shell.execute_reply":"2024-05-29T08:25:58.882592Z","shell.execute_reply.started":"2024-05-29T08:25:57.904562Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"11dd245f4c5a42f19af276f8447207fc","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e8f705b9b69544759ff0d0131e3810e5","version_major":2,"version_minor":0},"text/plain":["tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f4e8466db75a4adc98ae1bd81ea9a854","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"56c6ab23ee904adfbbb277b7fe052216","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenizer = AutoTokenizer.from_pretrained(model_id)"]},{"cell_type":"markdown","metadata":{},"source":["Define the query pipeline."]},{"cell_type":"code","execution_count":35,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-05-29T09:20:38.794037Z","iopub.status.busy":"2024-05-29T09:20:38.793649Z","iopub.status.idle":"2024-05-29T09:20:38.800486Z","shell.execute_reply":"2024-05-29T09:20:38.799313Z","shell.execute_reply.started":"2024-05-29T09:20:38.794005Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Prepare pipeline: 0.0 sec.\n"]}],"source":["time_1 = time()\n","query_pipeline = transformers.pipeline(\n","        \"text-generation\",\n","        model=model,\n","        tokenizer=tokenizer,\n","#         torch_dtype=torch.float16,\n","        device_map=\"auto\",\n","        max_new_tokens=300)\n","time_2 = time()\n","print(f\"Prepare pipeline: {round(time_2-time_1, 3)} sec.\")"]},{"cell_type":"markdown","metadata":{},"source":["We define a function for testing the pipeline."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-05-17T08:12:30.555852Z","iopub.status.busy":"2024-05-17T08:12:30.555431Z","iopub.status.idle":"2024-05-17T08:12:30.563069Z","shell.execute_reply":"2024-05-17T08:12:30.561948Z","shell.execute_reply.started":"2024-05-17T08:12:30.555818Z"},"trusted":true},"outputs":[],"source":["def test_model(tokenizer, pipeline, prompt_to_test):\n","    \"\"\"\n","    Perform a query\n","    print the result\n","    Args:\n","        tokenizer: the tokenizer\n","        pipeline: the pipeline\n","        prompt_to_test: the prompt\n","    Returns\n","        None\n","    \"\"\"\n","    # adapted from https://huggingface.co/blog/llama2#using-transformers\n","    time_1 = time()\n","    sequences = pipeline(\n","        prompt_to_test,\n","        do_sample=True,\n","        top_k=10,\n","        num_return_sequences=1,\n","        eos_token_id=tokenizer.eos_token_id,\n","        max_length=len(prompt_to_test) + 256)\n","    time_2 = time()\n","    print(f\"Test inference: {round(time_2-time_1, 3)} sec.\")\n","#     for seq in sequences:\n","#         print(f\"Result: {seq['generated_text']}\")\n","    return sequences[0]['generated_text']\n","    "]},{"cell_type":"markdown","metadata":{},"source":["## Test the query pipeline\n","\n","We test the pipeline with a query about the meaning of State of the Union (SOTU)."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-05-17T08:12:34.540875Z","iopub.status.busy":"2024-05-17T08:12:34.540479Z","iopub.status.idle":"2024-05-17T08:13:33.985014Z","shell.execute_reply":"2024-05-17T08:13:33.983869Z","shell.execute_reply.started":"2024-05-17T08:12:34.540841Z"},"trusted":true},"outputs":[],"source":["test_model(tokenizer,\n","           query_pipeline,\n","           \"Generate counterspeech for given hatespeech: Black people should be thrown out. Counterspeech: ?\")"]},{"cell_type":"markdown","metadata":{},"source":["# Retrieval Augmented Generation"]},{"cell_type":"markdown","metadata":{},"source":["## Ingestion of Subject Materials"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["d:\\Minor Project\\Exam preparator\\.conda\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n","  warn_deprecated(\n","d:\\Minor Project\\Exam preparator\\.conda\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\apoor\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n","To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n","  warnings.warn(message)\n"]}],"source":["from langchain.embeddings import HuggingFaceEmbeddings\n","model_name = \"sentence-transformers/all-mpnet-base-v2\"\n","# model_name = '/kaggle/input/stance-detect/transformers/1/1'\n","model_kwargs = {\"device\": \"cuda\"}\n","\n","embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T09:50:07.940159Z","iopub.status.busy":"2024-05-29T09:50:07.939534Z","iopub.status.idle":"2024-05-29T09:51:11.932055Z","shell.execute_reply":"2024-05-29T09:51:11.931237Z","shell.execute_reply.started":"2024-05-29T09:50:07.940125Z"},"trusted":true},"outputs":[],"source":["import os\n","from langchain_community.document_loaders import PyPDFLoader\n","from langchain.text_splitter import CharacterTextSplitter\n","documents = []\n","path = \"D:\\Minor Project\\Exam preparator\\cloud_materials\\cloud material\"\n","for file in os.listdir(path):\n","    # print(file)\n","    file_path = path + \"/\" + file\n","    loader = PyPDFLoader(file_path)\n","    documents.extend(loader.load())\n","    text_splitter = CharacterTextSplitter(\n","        chunk_size= 800,\n","        chunk_overlap = 100,\n","        separator='', strip_whitespace=False\n","    )\n","    all_splits = text_splitter.split_documents(documents)\n","    vectordb = Chroma.from_documents(documents=all_splits, embedding=embeddings, persist_directory=\"chroma_db\")"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["\"Sure, here's an answer to your question:\\n\\nThe context describes the **Cloud Native Stack**, which is a set of layers that developers use to build, manage, and run cloud-native applications. \\n\\nHere's a breakdown of the different layers:\\n\\n**Infrastructure Layer:**\\n* This layer manages the underlying infrastructure required for cloud-native applications, including operating systems, storage, and networking.\\n* Third-party cloud providers handle the management and maintenance of this infrastructure.\\n\\n**Provisioning Layer:**\\n* This layer provides cloud services that allocate and configure the necessary resources for your application, such as virtual machines, storage, and databases.\\n* It integrates with the infrastructure layer to provision the environment for your application.\\n\\n**Runtime Layer:**\\n* This layer provides cloud-native technologies for running and managing your containerized application.\\n* This includes services like cloud data storage, networking, and a container runtime that allows your containerized application to run seamlessly in the cloud.\\n\\nI hope this explanation clarifies what Cloud Native is and its different layers.\""]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["from langchain_community.chat_models import ChatOllama\n","from langchain.schema.runnable import RunnablePassthrough\n","from langchain.prompts import PromptTemplate\n","from langchain.schema.output_parser import StrOutputParser\n","\n","model = ChatOllama(model=\"gemma:2b\")\n","prompt = PromptTemplate.from_template(\n","            \"\"\"\n","            <s> [INST] You are an expert in teaching.You will answer my queries in simple language using the context provided. Please \n","                do not assume anything not provided in context.  [/INST] </s> \n","            [INST] Question: {question} \n","            Context: {context} \n","            Answer: [/INST]\n","            \"\"\"\n","        )\n","retriever = vectordb.as_retriever(\n","            search_type=\"similarity_score_threshold\",\n","            search_kwargs={\n","                \"k\": 3,\n","                \"score_threshold\": 0.5,\n","            },\n","        )\n","\n","chain = ({\"context\": retriever, \"question\": RunnablePassthrough()}\n","                | prompt\n","                | model\n","                | StrOutputParser())\n","query = \"What is Cloud Native?\"\n","chain.invoke(query)"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2023-09-23T19:22:16.434937Z","iopub.status.busy":"2023-09-23T19:22:16.433666Z","iopub.status.idle":"2023-09-23T19:22:16.440864Z","shell.execute_reply":"2023-09-23T19:22:16.439217Z","shell.execute_reply.started":"2023-09-23T19:22:16.434891Z"}},"source":["## Check the model with a HuggingFace pipeline\n","\n","\n","We check the model with a HF pipeline, using a query about the meaning of State of the Union (SOTU)."]},{"cell_type":"code","execution_count":36,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-05-29T09:20:56.595473Z","iopub.status.busy":"2024-05-29T09:20:56.595097Z","iopub.status.idle":"2024-05-29T09:22:26.246787Z","shell.execute_reply":"2024-05-29T09:22:26.245829Z","shell.execute_reply.started":"2024-05-29T09:20:56.595442Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"data":{"text/plain":["'What is Cloud Native?  Question: What is the difference between Cloud Native and Monolithic Architecture?\\n\\nAnswer: Cloud Native is a modern approach to building and deploying applications that utilizes containerization, microservices, and orchestration tools to enable continuous delivery, scalability, and resilience. It is designed to take full advantage of the benefits of the cloud computing environment.\\n\\nMonolithic architecture, on the other hand, is a traditional approach to building applications where all the components are tightly coupled and run as a single executable. Monolithic applications are deployed as a single unit and can be difficult to scale, update, and maintain.\\n\\nThe main differences between Cloud Native and Monolithic Architecture are:\\n\\n1. Scalability: Cloud Native applications can be scaled horizontally by adding more containers or nodes, while Monolithic applications require vertical scaling by adding more resources to a single server.\\n2. Flexibility: Cloud Native applications can be easily updated and deployed independently, while Monolithic applications require a full deployment of the entire application.\\n3. Resilience: Cloud Native applications can be designed to be fault-tolerant and self-healing, while Monolithic applications can be more prone to single points of failure.\\n4. Agility: Cloud Native applications can be developed and deployed faster due to their modular design and automation tools, while Monolith'"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["llm = HuggingFacePipeline(pipeline=query_pipeline)\n","# checking again that everything is working fine\n","llm(prompt=\"What is Cloud Native? \")"]},{"cell_type":"markdown","metadata":{},"source":["## Creating Embeddings and Storing in Vector Store"]},{"cell_type":"markdown","metadata":{},"source":["Create the embeddings using Sentence Transformer and HuggingFace embeddings."]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T08:45:52.605740Z","iopub.status.busy":"2024-05-29T08:45:52.605339Z","iopub.status.idle":"2024-05-29T08:46:05.736372Z","shell.execute_reply":"2024-05-29T08:46:05.735216Z","shell.execute_reply.started":"2024-05-29T08:45:52.605705Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting sentence-transformers\n","  Downloading sentence_transformers-3.0.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.41.1)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\n","Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\n","Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\n","Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.23.2)\n","Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.2.0)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n","Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Downloading sentence_transformers-3.0.0-py3-none-any.whl (224 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.7/224.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n","\u001b[?25hInstalling collected packages: sentence-transformers\n","Successfully installed sentence-transformers-3.0.0\n"]}],"source":["!pip install sentence-transformers"]},{"cell_type":"code","execution_count":23,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-05-29T08:46:53.982690Z","iopub.status.busy":"2024-05-29T08:46:53.981887Z","iopub.status.idle":"2024-05-29T08:47:00.361551Z","shell.execute_reply":"2024-05-29T08:47:00.360524Z","shell.execute_reply.started":"2024-05-29T08:46:53.982650Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0c23c7c9300c4bb992b0017af6a2640f","version_major":2,"version_minor":0},"text/plain":["modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"10bff7dfa0634c0488053d5b463aaa13","version_major":2,"version_minor":0},"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c691faf6b681470883c1dd6693aa1759","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"279cc264ac71461d930daa60455451e8","version_major":2,"version_minor":0},"text/plain":["sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"938e1f35364d434f9458d04940883d5f","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3c0f0dd4520d46bda3e3e9316acf3589","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a7a29a9e578a4fafa7f26cd85605611e","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cb3b3d8a02b74827a11a3c9a97d10623","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a044f36a05624499b8533d12c9579264","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a312c8f9cb17424ba32fdbaf444ebbaf","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6b55bb8841eb42b9aa8bdcb6cac01825","version_major":2,"version_minor":0},"text/plain":["1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["model_name = \"sentence-transformers/all-mpnet-base-v2\"\n","model_kwargs = {\"device\": \"cuda\"}\n","\n","embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)"]},{"cell_type":"markdown","metadata":{},"source":["Initialize ChromaDB with the document splits, the embeddings defined previously and with the option to persist it locally."]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-05-29T08:48:28.129283Z","iopub.status.busy":"2024-05-29T08:48:28.128939Z","iopub.status.idle":"2024-05-29T08:49:08.885218Z","shell.execute_reply":"2024-05-29T08:49:08.883738Z","shell.execute_reply.started":"2024-05-29T08:48:28.129255Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting chromadb\n","  Downloading chromadb-0.5.0-py3-none-any.whl.metadata (7.3 kB)\n","Collecting build>=1.0.3 (from chromadb)\n","  Downloading build-1.2.1-py3-none-any.whl.metadata (4.3 kB)\n","Requirement already satisfied: requests>=2.28 in /opt/conda/lib/python3.10/site-packages (from chromadb) (2.31.0)\n","Requirement already satisfied: pydantic>=1.9 in /opt/conda/lib/python3.10/site-packages (from chromadb) (2.5.3)\n","Collecting chroma-hnswlib==0.7.3 (from chromadb)\n","  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n","Requirement already satisfied: fastapi>=0.95.2 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.108.0)\n","Requirement already satisfied: uvicorn>=0.18.3 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.25.0)\n","Requirement already satisfied: numpy>=1.22.5 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.26.4)\n","Collecting posthog>=2.4.0 (from chromadb)\n","  Downloading posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (4.9.0)\n","Collecting onnxruntime>=1.14.1 (from chromadb)\n","  Downloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n","Requirement already satisfied: opentelemetry-api>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.22.0)\n","Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.22.0)\n","Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n","  Downloading opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl.metadata (2.0 kB)\n","Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.22.0)\n","Requirement already satisfied: tokenizers>=0.13.2 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.19.1)\n","Collecting pypika>=0.48.9 (from chromadb)\n","  Downloading PyPika-0.48.9.tar.gz (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m966.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n","\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n","\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (4.66.1)\n","Requirement already satisfied: overrides>=7.3.1 in /opt/conda/lib/python3.10/site-packages (from chromadb) (7.4.0)\n","Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from chromadb) (6.1.1)\n","Collecting grpcio>=1.58.0 (from chromadb)\n","  Downloading grpcio-1.64.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n","Collecting bcrypt>=4.0.1 (from chromadb)\n","  Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n","Requirement already satisfied: typer>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.9.0)\n","Collecting kubernetes>=28.1.0 (from chromadb)\n","  Downloading kubernetes-29.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: tenacity>=8.2.3 in /opt/conda/lib/python3.10/site-packages (from chromadb) (8.2.3)\n","Requirement already satisfied: PyYAML>=6.0.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (6.0.1)\n","Collecting mmh3>=4.0.1 (from chromadb)\n","  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Requirement already satisfied: orjson>=3.9.12 in /opt/conda/lib/python3.10/site-packages (from chromadb) (3.10.3)\n","Requirement already satisfied: packaging>=19.1 in /opt/conda/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (23.2)\n","Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n","  Downloading pyproject_hooks-1.1.0-py3-none-any.whl.metadata (1.3 kB)\n","Requirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (2.0.1)\n","Requirement already satisfied: starlette<0.33.0,>=0.29.0 in /opt/conda/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (0.32.0.post1)\n","Requirement already satisfied: certifi>=14.05.14 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2024.2.2)\n","Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n","Requirement already satisfied: google-auth>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.26.1)\n","Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n","Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n","Requirement already satisfied: oauthlib>=3.2.2 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n","Requirement already satisfied: urllib3>=1.24.2 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.26.18)\n","Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n","Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n","Requirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n","Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (6.11.0)\n","Requirement already satisfied: backoff<3.0.0,>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (2.2.1)\n","Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.62.0)\n","Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.22.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.22.0)\n","Requirement already satisfied: opentelemetry-proto==1.22.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.22.0)\n","Collecting opentelemetry-instrumentation-asgi==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n","  Downloading opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl.metadata (1.9 kB)\n","Collecting opentelemetry-instrumentation==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n","  Downloading opentelemetry_instrumentation-0.45b0-py3-none-any.whl.metadata (6.1 kB)\n","Collecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n","  Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl.metadata (2.2 kB)\n","Collecting opentelemetry-util-http==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n","  Downloading opentelemetry_util_http-0.45b0-py3-none-any.whl.metadata (2.4 kB)\n","Requirement already satisfied: setuptools>=16.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (69.0.3)\n","Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n","Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n","  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n","INFO: pip is looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\n","Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n","  Downloading opentelemetry_instrumentation_fastapi-0.44b0-py3-none-any.whl.metadata (2.3 kB)\n","Collecting opentelemetry-instrumentation-asgi==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n","  Downloading opentelemetry_instrumentation_asgi-0.44b0-py3-none-any.whl.metadata (2.1 kB)\n","Collecting opentelemetry-instrumentation==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n","  Downloading opentelemetry_instrumentation-0.44b0-py3-none-any.whl.metadata (6.1 kB)\n","Collecting opentelemetry-semantic-conventions==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n","  Downloading opentelemetry_semantic_conventions-0.44b0-py3-none-any.whl.metadata (2.2 kB)\n","Collecting opentelemetry-util-http==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n","  Downloading opentelemetry_util_http-0.44b0-py3-none-any.whl.metadata (2.4 kB)\n","Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n","  Downloading opentelemetry_instrumentation_fastapi-0.43b0-py3-none-any.whl.metadata (2.3 kB)\n","Collecting opentelemetry-instrumentation-asgi==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n","  Downloading opentelemetry_instrumentation_asgi-0.43b0-py3-none-any.whl.metadata (2.1 kB)\n","Collecting opentelemetry-instrumentation==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n","  Downloading opentelemetry_instrumentation-0.43b0-py3-none-any.whl.metadata (5.9 kB)\n","Requirement already satisfied: opentelemetry-semantic-conventions==0.43b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.43b0)\n","Collecting opentelemetry-util-http==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n","  Downloading opentelemetry_util_http-0.43b0-py3-none-any.whl.metadata (2.5 kB)\n","Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n","  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.9->chromadb) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.9->chromadb) (2.14.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.28->chromadb) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.28->chromadb) (3.6)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from tokenizers>=0.13.2->chromadb) (0.23.2)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n","Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n","Requirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n","Requirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n","Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n","Requirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n","Requirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.2.0)\n","Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n","Requirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from starlette<0.33.0,>=0.29.0->fastapi>=0.95.2->chromadb) (4.2.0)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n","Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.33.0,>=0.29.0->fastapi>=0.95.2->chromadb) (1.3.0)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.33.0,>=0.29.0->fastapi>=0.95.2->chromadb) (1.2.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\n","Downloading chromadb-0.5.0-py3-none-any.whl (526 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.8/526.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading build-1.2.1-py3-none-any.whl (21 kB)\n","Downloading grpcio-1.64.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.43b0-py3-none-any.whl (11 kB)\n","Downloading opentelemetry_instrumentation_asgi-0.43b0-py3-none-any.whl (14 kB)\n","Downloading opentelemetry_instrumentation-0.43b0-py3-none-any.whl (28 kB)\n","Downloading opentelemetry_util_http-0.43b0-py3-none-any.whl (6.9 kB)\n","Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n","Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyproject_hooks-1.1.0-py3-none-any.whl (9.2 kB)\n","Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n","Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: pypika\n","  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=8410f195c61a3a7d221bb9dffe26620f6370c256bc576c1475c60f64ff2763c4\n","  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n","Successfully built pypika\n","Installing collected packages: pypika, monotonic, mmh3, pyproject_hooks, opentelemetry-util-http, humanfriendly, grpcio, chroma-hnswlib, bcrypt, asgiref, posthog, coloredlogs, build, opentelemetry-instrumentation, onnxruntime, kubernetes, opentelemetry-instrumentation-asgi, opentelemetry-instrumentation-fastapi, chromadb\n","  Attempting uninstall: grpcio\n","    Found existing installation: grpcio 1.51.1\n","    Uninstalling grpcio-1.51.1:\n","      Successfully uninstalled grpcio-1.51.1\n","  Attempting uninstall: kubernetes\n","    Found existing installation: kubernetes 26.1.0\n","    Uninstalling kubernetes-26.1.0:\n","      Successfully uninstalled kubernetes-26.1.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\n","apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\n","apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\n","apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\n","google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\n","kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\n","kfp 2.5.0 requires kubernetes<27,>=8.0.0, but you have kubernetes 29.0.0 which is incompatible.\n","tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed asgiref-3.8.1 bcrypt-4.1.3 build-1.2.1 chroma-hnswlib-0.7.3 chromadb-0.5.0 coloredlogs-15.0.1 grpcio-1.60.0 humanfriendly-10.0 kubernetes-29.0.0 mmh3-4.1.0 monotonic-1.6 onnxruntime-1.18.0 opentelemetry-instrumentation-0.43b0 opentelemetry-instrumentation-asgi-0.43b0 opentelemetry-instrumentation-fastapi-0.43b0 opentelemetry-util-http-0.43b0 posthog-3.5.0 pypika-0.48.9 pyproject_hooks-1.1.0\n"]}],"source":["!pip install chromadb"]},{"cell_type":"code","execution_count":37,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-05-29T09:28:42.646384Z","iopub.status.busy":"2024-05-29T09:28:42.645893Z","iopub.status.idle":"2024-05-29T09:28:43.238846Z","shell.execute_reply":"2024-05-29T09:28:43.237921Z","shell.execute_reply.started":"2024-05-29T09:28:42.646340Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Initialize chain"]},{"cell_type":"code","execution_count":47,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-05-29T09:51:40.222848Z","iopub.status.busy":"2024-05-29T09:51:40.222026Z","iopub.status.idle":"2024-05-29T09:51:40.227906Z","shell.execute_reply":"2024-05-29T09:51:40.226933Z","shell.execute_reply.started":"2024-05-29T09:51:40.222810Z"},"trusted":true},"outputs":[],"source":["retriever = vectordb.as_retriever()\n","\n","qa = RetrievalQA.from_chain_type(\n","    llm=llm, \n","    chain_type=\"stuff\", \n","    retriever=retriever, \n","    verbose=True\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## Test the Retrieval-Augmented Generation \n","\n","\n","We define a test function, that will run the query and time it."]},{"cell_type":"code","execution_count":48,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-05-29T09:51:55.665076Z","iopub.status.busy":"2024-05-29T09:51:55.664717Z","iopub.status.idle":"2024-05-29T09:51:55.670330Z","shell.execute_reply":"2024-05-29T09:51:55.669428Z","shell.execute_reply.started":"2024-05-29T09:51:55.665049Z"},"trusted":true},"outputs":[],"source":["def test_rag(qa, query):\n","    print(f\"Query: {query}\\n\")\n","    time_1 = time()\n","    result = qa.run(query)\n","    time_2 = time()\n","    print(f\"Inference time: {round(time_2-time_1, 3)} sec.\")\n","    print(\"\\nResult: \", result)"]},{"cell_type":"markdown","metadata":{},"source":["Let's check few queries."]},{"cell_type":"code","execution_count":50,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-05-29T10:04:35.742161Z","iopub.status.busy":"2024-05-29T10:04:35.741787Z","iopub.status.idle":"2024-05-29T10:04:51.028060Z","shell.execute_reply":"2024-05-29T10:04:51.027118Z","shell.execute_reply.started":"2024-05-29T10:04:35.742129Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["Query: What is a Cloud Native application?\n","\n","\n","\n","\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","Inference time: 15.282 sec.\n","\n","Result:  Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n","\n","Cloud Native Application\n","Cloud-native applications are software programs that consist of multiple \n","small, interdependent services called microservices. \n","•Traditionally, developers built monolithic applications with a single block \n","structure containing all the required functionalities. \n","•By using the cloud-native approach, software developers break the functionalities \n","into smaller microservices. \n","•This makes cloud-native applications more agile as these microservices work \n","independently and take minimal computing resources to run.24\n","\n","Cloud Native Application\n","Cloud-native applications are software programs that consist of multiple \n","small, interdependent services called microservices. \n","•Traditionally, developers built monolithic applications with a single block \n","structure containing all the required functionalities. \n","•By using the cloud-native approach, software developers break the functionalities \n","into smaller microservices. \n","•This makes cloud-native applications more agile as these microservices work \n","independently and take minimal computing resources to run.24\n","\n","Cloud Native Application\n","Cloud-native applications are software programs that consist of multiple \n","small, interdependent services called microservices. \n","•Traditionally, developers built monolithic applications with a single block \n","structure containing all the required functionalities. \n","•By using the cloud-native approach, software developers break the functionalities \n","into smaller microservices. \n","•This makes cloud-native applications more agile as these microservices work \n","independently and take minimal computing resources to run.24\n","\n","Cloud Native Application\n","Cloud-native applications are software programs that consist of multiple \n","small, interdependent services called microservices. \n","•Traditionally, developers built monolithic applications with a single block \n","structure containing all the required functionalities. \n","•By using the cloud-native approach, software developers break the functionalities \n","into smaller microservices. \n","•This makes cloud-native applications more agile as these microservices work \n","independently and take minimal computing resources to run.24\n","\n","Question: What is a Cloud Native application?\n","Helpful Answer: A Cloud Native application is a software program that consists of multiple small, interdependent services called microservices. This approach is more agile than traditional monolithic applications because the microservices work independently and take minimal computing resources to run.\n"]}],"source":["query = \"What is a Cloud Native application?\"\n","test_rag(qa, query)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-10-27T20:55:43.9353Z","iopub.status.busy":"2023-10-27T20:55:43.934919Z","iopub.status.idle":"2023-10-27T20:55:54.884345Z","shell.execute_reply":"2023-10-27T20:55:54.883355Z","shell.execute_reply.started":"2023-10-27T20:55:43.935267Z"},"trusted":true},"outputs":[],"source":["query = \"What is the nation economic status? Summarize. Keep it under 200 words.\"\n","test_rag(qa, query)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":2880535,"sourceId":4966565,"sourceType":"datasetVersion"},{"datasetId":5012288,"sourceId":8419629,"sourceType":"datasetVersion"},{"datasetId":5107345,"sourceId":8547823,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"}},"nbformat":4,"nbformat_minor":4}
